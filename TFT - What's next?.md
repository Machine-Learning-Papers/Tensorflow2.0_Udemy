# What's next?

In this section, we created a TensorFlow Transform data pipeline - from importing the dataset to preparing it for a model.


However, what’s next?


The TensorFlow Transform (TFT) is a part of the technology stack called TensorFlow Extended, which is made to carry the whole deep learning project end-to-end. The TFT comes after Data Validation library and before model analysis part in the pipeline.


The TFT library is always used to create automated data preprocessing pipelines. It lays on the Apache Beam, and because of that we can create fast, reliable, data preprocessing pipelines, used in production.


I’ve provided for you an example of the Data Pipeline developed in a more advanced way, which was too complex to start with. So, if you want to learn more about TFT, this link is a great way to start.


1. Advanced Data pipeline created using the TensorFlow Transform (TFT):

    https://www.tensorflow.org/tfx/tutorials/transform/census


If you want to learn more about Apache Beam technology, here are some great links to start with:


1. Great starting point for Apache Beam learning:

    https://medium.com/analytics-vidhya/apache-beam-a-beginners-approach-4783dfc6fea


2. Building Data Pipelines using Python:

    https://towardsdatascience.com/hands-on-apache-beam-building-data-pipelines-in-python-6548898b66a5


3. Apache Beam documentation:

    https://beam.apache.org/documentation/
